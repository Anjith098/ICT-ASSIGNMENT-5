{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aRvzWzbhcnp"
   },
   "source": [
    "#Data Acquisition Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "734JDyUNq8fH"
   },
   "source": [
    "## Q1. Write Python code to create a new file named \"sample_data.txt\" in your documents folder and write the following content to it\n",
    "\n",
    "ICTAK\n",
    "\n",
    "Thejaswini,\n",
    "\n",
    "Technopark Rd,\n",
    "\n",
    "Technopark Campus,\n",
    "\n",
    "Thiruvananthapuram,\n",
    "\n",
    "Kerala 695581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ieKhqBr-nl7s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created successfully at: C:\\Users\\745an/Documents\\sample_data.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_and_write_file():\n",
    "    documents_folder = os.path.expanduser(\"~/Documents\")\n",
    "    file_path = os.path.join(documents_folder, \"sample_data.txt\")\n",
    "    \n",
    "    content = \"\"\"ICTAK\n",
    "\n",
    "Thejaswini,\n",
    "\n",
    "Technopark Rd,\n",
    "\n",
    "Technopark Campus,\n",
    "\n",
    "Thiruvananthapuram,\n",
    "\n",
    "Kerala 695581\"\"\"\n",
    "    \n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(content)\n",
    "    \n",
    "    print(f\"File created successfully at: {file_path}\")\n",
    "create_and_write_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ6hQOJpimNv"
   },
   "source": [
    "## Q2. Write Python code to read and print the contents in \"sample_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vRnilPQgnrPG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contents:\n",
      "ICTAK\n",
      "\n",
      "Thejaswini,\n",
      "\n",
      "Technopark Rd,\n",
      "\n",
      "Technopark Campus,\n",
      "\n",
      "Thiruvananthapuram,\n",
      "\n",
      "Kerala 695581\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def read_and_print_file():\n",
    "    documents_folder = os.path.expanduser(\"~/Documents\")\n",
    "    file_path = os.path.join(documents_folder, \"sample_data.txt\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            content = file.read()\n",
    "            print(\"File contents:\")\n",
    "            print(content)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please make sure it exists.\")\n",
    "read_and_print_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aHquDcErda-"
   },
   "source": [
    "## Q3. Write Python code to check if \"sample_data.txt\" exists in documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vY5TEsxunsKh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data.txt exists in the Documents folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_file_exists():\n",
    "    documents_folder = os.path.expanduser(\"~/Documents\")\n",
    "    file_path = os.path.join(documents_folder, \"sample_data.txt\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(\"sample_data.txt exists in the Documents folder.\")\n",
    "    else:\n",
    "        print(\"sample_data.txt does not exist in the Documents folder.\")\n",
    "\n",
    "check_file_exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCWITkmopblI"
   },
   "source": [
    "## Q4: Save the following dataframe content to a CSV file (data.csv) in your downloads folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3THwBOGpP9F"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\"Id\": [1, 2, 3],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Subject\": [\"Science\", \"Maths\", \"History\"]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Joc7XafnntaG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully at: C:\\Users\\745an/Downloads\\data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_dataframe_to_csv():\n",
    "    data = {\n",
    "        \"Id\": [1, 2, 3],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Subject\": [\"Science\", \"Maths\", \"History\"]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    downloads_folder = os.path.expanduser(\"~/Downloads\")\n",
    "    file_path = os.path.join(downloads_folder, \"data.csv\")\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"CSV file saved successfully at: {file_path}\")\n",
    "\n",
    "save_dataframe_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VF0nJjGElq0A"
   },
   "source": [
    "## Q5: Save the above dataframe content to an Excel (data.xlsx, sheet name: Sheet1) file in your documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZtOFb7ZJnu1m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved successfully at: C:\\Users\\745an/Documents\\data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_dataframe_to_excel():\n",
    "    data = {\n",
    "        \"Id\": [1, 2, 3],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Subject\": [\"Science\", \"Maths\", \"History\"]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    documents_folder = os.path.expanduser(\"~/Documents\")\n",
    "    file_path = os.path.join(documents_folder, \"data.xlsx\")\n",
    "    \n",
    "    with pd.ExcelWriter(file_path, engine=\"xlsxwriter\") as writer:\n",
    "        df.to_excel(writer, sheet_name=\"Sheet1\", index=False)\n",
    "    \n",
    "    print(f\"Excel file saved successfully at: {file_path}\")\n",
    "\n",
    "save_dataframe_to_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amF6kxMQmdgF"
   },
   "source": [
    "## Q6. Write code to get the list of files in your Downloads folder and save it to a CSV file name \"download_list.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nVP86z3dnvwz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully at: C:\\Users\\745an/Downloads\\download_list.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def list_files_and_save_to_csv():\n",
    "    downloads_folder = os.path.expanduser(\"~/Downloads\")\n",
    "    \n",
    "    files = os.listdir(downloads_folder)\n",
    "    df = pd.DataFrame({\"Files\": files})\n",
    "    file_path = os.path.join(downloads_folder, \"download_list.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"CSV file saved successfully at: {file_path}\")\n",
    "list_files_and_save_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR7I4R5bnV2w"
   },
   "source": [
    "## Q7. Write Python code to save the contents of the given random_array variable as a numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vHXYRxnDnJzA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_array = np.random.rand(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ihhSKJF9n3NP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array saved successfully as 'random_array.npy'.\n"
     ]
    }
   ],
   "source": [
    "np.save(\"random_array.npy\", random_array)\n",
    "print(\"NumPy array saved successfully as 'random_array.npy'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7XfHgGAzNIl"
   },
   "source": [
    "## Q8. Write python code to save the contents of the above numpy file as text file named \"random.txt\" with a delimitter of \";\" to Documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Du3LRbaKbpeg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file saved successfully at: C:\\Users\\745an/Documents\\random.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def save_numpy_to_text():\n",
    "    documents_folder = os.path.expanduser(\"~/Documents\")\n",
    "    file_path = os.path.join(documents_folder, \"random.txt\")\n",
    "    random_array = np.load(\"random_array.npy\")\n",
    "\n",
    "    np.savetxt(file_path, random_array, delimiter=\";\", fmt=\"%.6f\")\n",
    "\n",
    "    print(f\"Text file saved successfully at: {file_path}\")\n",
    "\n",
    "save_numpy_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJSaX0Rg151y"
   },
   "source": [
    "## Download and analyze Bike Sharing Dataset (hour.csv) for UCI Irvin Repository (https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) and answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wt4mxq32U6H"
   },
   "source": [
    "## Q9. What is the size of the dataset? (Number of rows and columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Pj0I0JhF2EEg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2: 17379 rows, 17 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "file2 = \"ict-5/hour.csv\"  \n",
    "\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "print(f\"File 2: {df2.shape[0]} rows, {df2.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbDnC_i438m8"
   },
   "source": [
    "# Q10. What are the data types of each column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_YJIqJEZ3-DC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in first file:\n",
      " instant         int64\n",
      "dteday         object\n",
      "season          int64\n",
      "yr              int64\n",
      "mnth            int64\n",
      "holiday         int64\n",
      "weekday         int64\n",
      "workingday      int64\n",
      "weathersit      int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "hum           float64\n",
      "windspeed     float64\n",
      "casual          int64\n",
      "registered      int64\n",
      "cnt             int64\n",
      "dtype: object \n",
      "\n",
      "Data types in second file:\n",
      " instant         int64\n",
      "dteday         object\n",
      "season          int64\n",
      "yr              int64\n",
      "mnth            int64\n",
      "hr              int64\n",
      "holiday         int64\n",
      "weekday         int64\n",
      "workingday      int64\n",
      "weathersit      int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "hum           float64\n",
      "windspeed     float64\n",
      "casual          int64\n",
      "registered      int64\n",
      "cnt             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = \"ict-5/day.csv\"  \n",
    "file2 = \"ict-5/hour.csv\" \n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "print(\"Data types in first file:\\n\", df1.dtypes, \"\\n\")\n",
    "print(\"Data types in second file:\\n\", df2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi0jHMq-3_NI"
   },
   "source": [
    "## Q11. Are there any missing values in the dataset? If so, which columns have missing values and how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mct7F2M-3-kQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in second file:\n",
      "No missing values.\n"
     ]
    }
   ],
   "source": [
    "file2 = \"ict-5/hour.csv\"  \n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "missing_values_2 = df2.isnull().sum()\n",
    "\n",
    "missing_values_2 = missing_values_2[missing_values_2 > 0]\n",
    "\n",
    "print(\"\\nMissing values in second file:\")\n",
    "print(missing_values_2 if not missing_values_2.empty else \"No missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew__56Iq4BMK"
   },
   "source": [
    "## Q.12. For the windspeed column, calculate the mean, median, and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucijLTNA4Clr"
   },
   "source": [
    "\n",
    "file2 = \"ict-5/hour.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "\n",
    "stats2 = {\n",
    "    \"Mean\": df2[\"windspeed\"].mean(),\n",
    "    \"Median\": df2[\"windspeed\"].median(),\n",
    "    \"Std Dev\": df2[\"windspeed\"].std(),\n",
    "}\n",
    "\n",
    "print(\"Windspeed Statistics for Second File:\", stats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dHaYtuP4C78"
   },
   "source": [
    "## Q13. Identify any potential outliers in a numerical column of your choice. Explain your approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in instant column:\n",
      " Series([], Name: instant, dtype: int64)\n",
      "Number of outliers: 0\n"
     ]
    }
   ],
   "source": [
    "#FOR HOUR.CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path = \"ict-5/hour.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "column_name = \"instant\"\n",
    "\n",
    "Q1 = df[column_name].quantile(0.25)\n",
    "Q3 = df[column_name].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
    "\n",
    "print(f\"Outliers in {column_name} column:\\n\", outliers[column_name])\n",
    "print(f\"Number of outliers: {outliers.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLANATION FOR THIS APPROACH\n",
    "\n",
    "#I used IQR approach to find outliers by creating a code to find Q1 and Q3 . Then substituting this values in the formula of lower bound and upper bound \n",
    "#And then using the condition for outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14sUq8ZF4E88"
   },
   "source": [
    "## Q.14 Find the correlation between numerical columns and discuss any interesting relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnAOuuwt4Hmb"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru-xlbd44IAY"
   },
   "source": [
    "## Q.15 Based on your analysis, provide a brief summary of any insights or patterns you discovered in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15NUIdxK4I03"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n",
    "\n",
    "#BASED ON MY ANALYSIS TILL NOW OF THE DATASETS HOURS.CSV AND DAY.CSV THE NUMBERS OF COULUMNS AND ROWS FO#R THESE TWO DATASETS ARE :  Fil.e 1: 731 rows, 16 columns\n",
    "#File 2: 17379 rows, 17 columns.\n",
    "#THE DATATYPES FOR EACH COLUMN ARE SHHOWN IN QUESTION NUMBER 10.\n",
    "#THE TWO DATASETS HAVE NO MISSING VALUES.\n",
    "# mean, median, and standard deviation for windspeed column are:\n",
    "#Windspeed Statistics for First File: {'Mean': np.float64(0.190486211627907), 'Median': np.float64(0.180975), 'Std Dev': np.float64(0.07749787068166941)}\n",
    "#Windspeed Statistics for Second File: {'Mean': np.float64(0.1900976063064618), 'Median': np.float64(0.194), 'Std Dev': np.float64(0.12234022857279049)}\n",
    "#NO OUTLIERS FOR FOR BOTH DATASETS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMGro15Q5WhF"
   },
   "source": [
    "## Q.16 In which season (Spring, Summer, Fall, Winter) people rented bikes the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KhlVV_bK5jxm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Bike Rentals by Season (File 1):\n",
      "season\n",
      "Fall      1061129\n",
      "Summer     918589\n",
      "Winter     841613\n",
      "Spring     471348\n",
      "Name: cnt, dtype: int64\n",
      "\n",
      "Total Bike Rentals by Season (File 2):\n",
      "season\n",
      "Fall      1061129\n",
      "Summer     918589\n",
      "Winter     841613\n",
      "Spring     471348\n",
      "Name: cnt, dtype: int64\n",
      "\n",
      " In File 1, people rented bikes the most in **Fall**.\n",
      " In File 2, people rented bikes the most in **Fall**.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file1 = \"ict-5/day.csv\"  \n",
    "file2 = \"ict-5/hour.csv\"  \n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "season_map = {1: \"Spring\", 2: \"Summer\", 3: \"Fall\", 4: \"Winter\"}\n",
    "df1[\"season\"] = df1[\"season\"].map(season_map)\n",
    "df2[\"season\"] = df2[\"season\"].map(season_map)\n",
    "\n",
    "season_rentals_1 = df1.groupby(\"season\")[\"cnt\"].sum().sort_values(ascending=False)\n",
    "season_rentals_2 = df2.groupby(\"season\")[\"cnt\"].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Total Bike Rentals by Season (File 1):\")\n",
    "print(season_rentals_1)\n",
    "\n",
    "print(\"\\nTotal Bike Rentals by Season (File 2):\")\n",
    "print(season_rentals_2)\n",
    "\n",
    "most_popular_season_1 = season_rentals_1.idxmax()\n",
    "most_popular_season_2 = season_rentals_2.idxmax()\n",
    "\n",
    "print(f\"\\n In File 1, people rented bikes the most in **{most_popular_season_1}**.\")\n",
    "print(f\" In File 2, people rented bikes the most in **{most_popular_season_2}**.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eudb_1Lb5sVc"
   },
   "source": [
    "## Q.17 What is the peak hour in which bike rents the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "p0xSgv8g50yt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Bike Rentals by Hour:\n",
      " hr\n",
      "0      39130\n",
      "1      24164\n",
      "2      16352\n",
      "3       8174\n",
      "4       4428\n",
      "5      14261\n",
      "6      55132\n",
      "7     154171\n",
      "8     261001\n",
      "9     159438\n",
      "10    126257\n",
      "11    151320\n",
      "12    184414\n",
      "13    184919\n",
      "14    175652\n",
      "15    183149\n",
      "16    227748\n",
      "17    336860\n",
      "18    309772\n",
      "19    226789\n",
      "20    164550\n",
      "21    125445\n",
      "22     95612\n",
      "23     63941\n",
      "Name: cnt, dtype: int64\n",
      "\n",
      " The peak hour for bike rentals is **17:00** with 336860 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"ict-5/hour.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "hourly_rentals = df.groupby(\"hr\")[\"cnt\"].sum()\n",
    "\n",
    "peak_hour = hourly_rentals.idxmax()\n",
    "peak_rentals = hourly_rentals.max()\n",
    "\n",
    "print(\"Total Bike Rentals by Hour:\\n\", hourly_rentals)\n",
    "print(f\"\\n The peak hour for bike rentals is **{peak_hour}:00** with {peak_rentals} rentals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7rArqGQ6ji4"
   },
   "source": [
    "## Q.18 In which day of a week bikes rents out most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GPCbpsx6oYE"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFO_Twk66qw-"
   },
   "source": [
    "# Q.19 In which hour Casual users rents bikes the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "59CHoEUt66GR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Casual Bike Rentals by Hour:\n",
      " hr\n",
      "0      7375\n",
      "1      4709\n",
      "2      3412\n",
      "3      1893\n",
      "4       874\n",
      "5      1012\n",
      "6      3017\n",
      "7      8037\n",
      "8     15761\n",
      "9     22458\n",
      "10    33789\n",
      "11    43286\n",
      "12    49718\n",
      "13    52713\n",
      "14    55089\n",
      "15    54606\n",
      "16    53834\n",
      "17    54220\n",
      "18    44496\n",
      "19    35505\n",
      "20    26378\n",
      "21    20570\n",
      "22    16200\n",
      "23    11065\n",
      "Name: casual, dtype: int64\n",
      "\n",
      " Casual users rent bikes the most at **14:00** with 55089 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"ict-5/hour.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "hourly_casual_rentals = df.groupby(\"hr\")[\"casual\"].sum()\n",
    "\n",
    "peak_hour = hourly_casual_rentals.idxmax()\n",
    "peak_rentals = hourly_casual_rentals.max()\n",
    "\n",
    "print(\"Total Casual Bike Rentals by Hour:\\n\", hourly_casual_rentals)\n",
    "\n",
    "print(f\"\\n Casual users rent bikes the most at **{peak_hour}:00** with {peak_rentals} rentals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtvgNN-U69rh"
   },
   "source": [
    "## Q.20 What is the maximum temperature observed in each of the seasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_NwDHv57tLT"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
